{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import CENSUS_25\n",
    "\n",
    "BUFFER_DIST = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((586570.163 4833163.341, 587570.163 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((586570.163 4834163.341, 587570.163 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((586570.163 4835163.341, 587570.163 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((586570.163 4836163.341, 587570.163 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((586570.163 4837163.341, 587570.163 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry\n",
       "0  POLYGON ((586570.163 4833163.341, 587570.163 4...\n",
       "1  POLYGON ((586570.163 4834163.341, 587570.163 4...\n",
       "2  POLYGON ((586570.163 4835163.341, 587570.163 4...\n",
       "3  POLYGON ((586570.163 4836163.341, 587570.163 4...\n",
       "4  POLYGON ((586570.163 4837163.341, 587570.163 4..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GTA municipalities boundary\n",
    "gta = gpd.read_file(\"../data/geo/regions/TMUN.gpkg\")\n",
    "\n",
    "# Ensure geometry validity\n",
    "gta[\"geometry\"] = gta[\"geometry\"].apply(make_valid)\n",
    "\n",
    "# Reproject\n",
    "CRS_METERS = \"EPSG:32617\"\n",
    "gta_proj = gta.to_crs(CRS_METERS)\n",
    "\n",
    "# Dissolve for boundary use\n",
    "gta_boundary = gta_proj.dissolve().geometry.values[0]  # shapely Polygon/MultiPolygon\n",
    "\n",
    "# Create a 5 km buffer around GTA\n",
    "gta_buffer = gta_boundary.buffer(BUFFER_DIST)\n",
    "\n",
    "# Grid resolution\n",
    "cell_size = 1000  # meters\n",
    "\n",
    "# Create bounding box for grid\n",
    "minx, miny, maxx, maxy = gta_buffer.bounds  # use buffer bounds\n",
    "\n",
    "# Grid coordinates\n",
    "x_coords = np.arange(minx, maxx + cell_size, cell_size)\n",
    "y_coords = np.arange(miny, maxy + cell_size, cell_size)\n",
    "\n",
    "# Create squares only inside GTA buffer\n",
    "grid_polys = []\n",
    "for x in x_coords:\n",
    "    for y in y_coords:\n",
    "        poly = Polygon([\n",
    "            (x, y),\n",
    "            (x + cell_size, y),\n",
    "            (x + cell_size, y + cell_size),\n",
    "            (x, y + cell_size)\n",
    "        ])\n",
    "        if poly.intersects(gta_buffer):\n",
    "            grid_polys.append(poly)\n",
    "\n",
    "grid = gpd.GeoDataFrame({\"geometry\": grid_polys}, crs=CRS_METERS)\n",
    "\n",
    "# Save as GeoPackage\n",
    "OUT_PATH = \"../data/geo/regions/TMUN_squares_fullgrid.gpkg\"\n",
    "grid.to_file(OUT_PATH, driver=\"GPKG\")\n",
    "\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpolating year 1971...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "year 1971 tracts: 100%|██████████| 422/422 [00:04<00:00, 100.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interpolated squares for 1971 -> ../data/language/1971/num_speakers_squares_1971.gpkg\n",
      "\n",
      "Interpolating year 1996...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "year 1996 tracts: 100%|██████████| 713/713 [00:09<00:00, 75.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interpolated squares for 1996 -> ../data/language/1996/num_speakers_squares_1996.gpkg\n",
      "\n",
      "Interpolating year 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "year 2021 tracts: 100%|██████████| 1049/1049 [00:18<00:00, 55.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interpolated squares for 2021 -> ../data/language/2021/num_speakers_squares_2021.gpkg\n",
      "\n",
      "All years complete.\n"
     ]
    }
   ],
   "source": [
    "SQUARES_PATH = \"../data/geo/regions/TMUN_squares_fullgrid.gpkg\"\n",
    "OUT_PATTERN = \"../data/language/{year}/num_speakers_squares_{year}.gpkg\"\n",
    "\n",
    "def _ensure_out_dir(path_str):\n",
    "    Path(path_str).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load grid\n",
    "squares = gpd.read_file(SQUARES_PATH).to_crs(CRS_METERS).reset_index(drop=True)\n",
    "\n",
    "# Spatial index for intersections\n",
    "squares_sindex = squares.sindex\n",
    "\n",
    "# Main loop over census years\n",
    "for year in CENSUS_25:\n",
    "    print(f\"\\nInterpolating year {year}...\")\n",
    "\n",
    "    # Load tract-level counts\n",
    "    tract_path = f\"../data/language/{year}/num_speakers_tmun_{year}.gpkg\"\n",
    "    tracts = gpd.read_file(tract_path).to_crs(CRS_METERS)\n",
    "\n",
    "    # Columns to interpolate\n",
    "    num_cols = [c for c in tracts.columns if c.startswith(\"num_\") and c != \"geometry\"]\n",
    "    if \"num_tot\" not in num_cols and \"num_tot\" in tracts.columns:\n",
    "        num_cols.append(\"num_tot\")\n",
    "\n",
    "    # Prepare result GeoDataFrame\n",
    "    result = squares.copy()\n",
    "    for c in num_cols:\n",
    "        result[c] = 0.0\n",
    "\n",
    "    tracts[num_cols] = tracts[num_cols].astype(float)\n",
    "\n",
    "    # Distribute tract counts to intersecting squares\n",
    "    for idx, tract in tqdm(tracts.iterrows(), total=len(tracts), desc=f\"year {year} tracts\"):\n",
    "        tract_geom = tract.geometry\n",
    "        if tract_geom is None or tract_geom.is_empty:\n",
    "            continue\n",
    "        tract_area = tract_geom.area\n",
    "        if tract_area == 0 or np.isnan(tract_area):\n",
    "            continue\n",
    "\n",
    "        # candidate square indices whose bounding boxes intersect tract bbox\n",
    "        possible_idx = list(squares_sindex.intersection(tract_geom.bounds))\n",
    "        if not possible_idx:\n",
    "            continue\n",
    "\n",
    "        candidates = result.iloc[possible_idx]\n",
    "        intersections = candidates.geometry.intersection(tract_geom)\n",
    "        inter_areas = intersections.area\n",
    "        mask = inter_areas > 0\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        recv_idx = candidates.index[mask]\n",
    "        ratios = inter_areas[mask] / tract_area\n",
    "\n",
    "        for col in num_cols:\n",
    "            tract_value = tract[col] if pd.notnull(tract[col]) else 0.0\n",
    "            if tract_value == 0:\n",
    "                continue\n",
    "            apportioned = ratios * float(tract_value)\n",
    "            result.loc[recv_idx, col] += apportioned.values\n",
    "\n",
    "    # Ensure no negative values\n",
    "    for c in num_cols:\n",
    "        result[c] = result[c].clip(lower=0.0)\n",
    "\n",
    "    # Save interpolated squares\n",
    "    out_path = OUT_PATTERN.format(year=year)\n",
    "    _ensure_out_dir(out_path)\n",
    "    result.to_file(out_path, driver=\"GPKG\")\n",
    "    print(f\"Saved interpolated squares for {year} -> {out_path}\")\n",
    "\n",
    "print(\"\\nAll years complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1971…\n",
      "✓ Finished 1971\n",
      "Processing 1996…\n",
      "✓ Finished 1996\n",
      "Processing 2021…\n",
      "✓ Finished 2021\n"
     ]
    }
   ],
   "source": [
    "IN_PATTERN = \"../data/language/{year}/num_speakers_squares_{year}.gpkg\"\n",
    "PCT_PATTERN = \"../data/language/{year}/pct_speakers_squares_{year}.gpkg\"\n",
    "CENT_NUM_PATTERN = \"../data/language/{year}/num_speakers_centroid_{year}.gpkg\"\n",
    "CENT_PCT_PATTERN = \"../data/language/{year}/pct_speakers_centroid_{year}.gpkg\"\n",
    "\n",
    "for year in CENSUS_25:\n",
    "    print(f\"Processing {year}…\")\n",
    "\n",
    "    # Load NUM dataset\n",
    "    num_path = IN_PATTERN.format(year=year)\n",
    "    gdf_num = gpd.read_file(num_path)\n",
    "\n",
    "    lang_cols = [c for c in gdf_num.columns if c.startswith(\"num_\") and c != \"num_tot\"]\n",
    "\n",
    "    # Compute percentages\n",
    "    gdf_pct = gdf_num.copy()\n",
    "    EPS = 1e-9\n",
    "    safe_tot = gdf_pct[\"num_tot\"].replace(0, EPS)\n",
    "    for col in lang_cols:\n",
    "        lang = col.replace(\"num_\", \"\")\n",
    "        gdf_pct[f\"pct_{lang}\"] = (gdf_pct[col] / safe_tot * 100).round(2)\n",
    "\n",
    "    zero_mask = gdf_pct[\"num_tot\"] == 0\n",
    "    for col in gdf_pct.columns:\n",
    "        if col.startswith(\"pct_\"):\n",
    "            gdf_pct.loc[zero_mask, col] = 0\n",
    "\n",
    "    gdf_pct[\"num_tot\"] = gdf_pct[\"num_tot\"].round(2)\n",
    "    gdf_pct = gdf_pct.drop(columns=lang_cols)\n",
    "\n",
    "    # Save pct file\n",
    "    pct_path = PCT_PATTERN.format(year=year)\n",
    "    gdf_pct.to_file(pct_path, driver=\"GPKG\")\n",
    "\n",
    "    # Round NUM values\n",
    "    for col in lang_cols + [\"num_tot\"]:\n",
    "        gdf_num[col] = gdf_num[col].round(2)\n",
    "    gdf_num.to_file(num_path, driver=\"GPKG\")\n",
    "\n",
    "    # Centroid versions\n",
    "    gdf_num_cent = gdf_num.copy()\n",
    "    gdf_num_cent[\"geometry\"] = gdf_num_cent.centroid\n",
    "    gdf_num_cent.to_file(CENT_NUM_PATTERN.format(year=year), driver=\"GPKG\")\n",
    "\n",
    "    gdf_pct_cent = gdf_pct.copy()\n",
    "    gdf_pct_cent[\"geometry\"] = gdf_pct_cent.centroid\n",
    "    gdf_pct_cent.to_file(CENT_PCT_PATTERN.format(year=year), driver=\"GPKG\")\n",
    "\n",
    "    print(f\"✓ Finished {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 1971...\n",
      "✓ Saved ../data/language/1971/num_speakers_centroid_1971.json (2809 rows)\n",
      "Processing year 1996...\n",
      "✓ Saved ../data/language/1996/num_speakers_centroid_1996.json (2809 rows)\n",
      "Processing year 2021...\n",
      "✓ Saved ../data/language/2021/num_speakers_centroid_2021.json (2809 rows)\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "import json\n",
    "\n",
    "# Load GTA boundary in WGS84\n",
    "gta = gpd.read_file(\"../data/geo/regions/TMUN.gpkg\").to_crs(\"EPSG:4326\")\n",
    "gta_boundary = gta.dissolve().geometry.values[0]  # Polygon/MultiPolygon\n",
    "\n",
    "# --- NEW: Create a 5 km *expanded* boundary for filtering ---\n",
    "CRS_METERS = \"EPSG:32617\"\n",
    "\n",
    "# Reproject for accurate buffering\n",
    "gta_boundary_m = (\n",
    "    gpd.GeoSeries([gta_boundary], crs=\"EPSG:4326\")\n",
    "    .to_crs(CRS_METERS)\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "# Outward buffer: +5000 m\n",
    "gta_buffer_m = gta_boundary_m.buffer(BUFFER_DIST)\n",
    "\n",
    "# Convert back to WGS84 so it matches centroid CRS\n",
    "gta_boundary_expanded = (\n",
    "    gpd.GeoSeries([gta_buffer_m], crs=CRS_METERS)\n",
    "    .to_crs(\"EPSG:4326\")\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "EPS_THRESH = 0.0001  # treat counts <1 as null/no-data\n",
    "\n",
    "for year in CENSUS_25:\n",
    "    in_path = f\"../data/language/{year}/num_speakers_centroid_{year}.gpkg\"\n",
    "    out_path = f\"../data/language/{year}/num_speakers_centroid_{year}.json\"\n",
    "\n",
    "    print(f\"Processing year {year}...\")\n",
    "\n",
    "    # Load centroids\n",
    "    gdf = gpd.read_file(in_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Coordinates\n",
    "    gdf[\"x\"] = gdf.geometry.x\n",
    "    gdf[\"y\"] = gdf.geometry.y\n",
    "\n",
    "    # --- FILTER: keep only points within 5 km outside GTA ---\n",
    "    gdf = gdf[gdf.geometry.within(gta_boundary_expanded)].copy()\n",
    "\n",
    "    # Nullify tiny values\n",
    "    num_cols = [c for c in gdf.columns if c.startswith(\"num_\")]\n",
    "    for col in num_cols:\n",
    "        gdf[col] = gdf[col].where(gdf[col] >= EPS_THRESH, other=np.nan)\n",
    "\n",
    "    # Prepare export DataFrame\n",
    "    df = gdf[[\"x\", \"y\"] + num_cols]\n",
    "\n",
    "    # Export JSON\n",
    "    df.to_json(out_path, orient=\"records\", indent=2, force_ascii=False)\n",
    "\n",
    "    print(f\"✓ Saved {out_path} ({len(df)} rows)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
